{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitbaseconda255b5d88deff4dad9b265a4213ec9717",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def displayVertex(src, vertex, mode = 'run'):\n",
    "    # 展示有效vertex的Demo\n",
    "\n",
    "    # 读取视频\n",
    "    cap = cv2.VideoCapture(src)\n",
    "\n",
    "    # 创建随机颜色\n",
    "    color = np.random.randint(0, 255, (3000, 3))\n",
    "\n",
    "    # 获取第一帧，找到角点\n",
    "    ret, old_frame = cap.read()\n",
    "\n",
    "    # 获取图像中的角点，返回到p0中\n",
    "    p0 = vertex[0].reshape(-1, 1, 2)\n",
    "\n",
    "    # 创建一个蒙版用来画轨迹\n",
    "    mask = np.zeros_like(old_frame)\n",
    "\n",
    "    count = 1\n",
    "\n",
    "    while(1):\n",
    "        ret, frame = cap.read()\n",
    "        if type(frame) is type(None):\n",
    "            break\n",
    "\n",
    "        # 计算光流\n",
    "        p1 = vertex[count].reshape(-1, 1, 2)\n",
    "        count += 1\n",
    "\n",
    "        flag = ((np.sum(p0, axis = 2) >= 0) & (np.sum(p1, axis = 2) >= 0)).flatten()\n",
    "        good_old = p0[flag]\n",
    "        good_new = p1[flag]\n",
    "\n",
    "        # 画出轨迹\n",
    "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = new.ravel().astype('int')\n",
    "            c, d = old.ravel().astype('int')\n",
    "            mask = cv2.line(mask, (a, b), (c, d), color[i].tolist(), 2)\n",
    "            frame = cv2.circle(frame, (a, b), 5, color[i].tolist(), -1)\n",
    "        img = cv2.add(frame, mask)\n",
    "\n",
    "        # 展示\n",
    "        cv2.imshow('frame', img)\n",
    "        # cv2.imshow('frame_gray', frame_gray)\n",
    "        k = cv2.waitKey(mode == 'run') & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "        # 更新上一帧的图像和追踪点\n",
    "        p0 = p1\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "\n",
    "def orbFeature(img):\n",
    "    '''\n",
    "    输入彩色图像，输出屏蔽噪音的特征点\n",
    "    '''\n",
    "    orb = cv2.ORB_create(nfeatures = 300, scaleFactor = 2, firstLevel = 0)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.medianBlur(gray, 21)\n",
    "    gray = sharpen(gray)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    keypoints, _ = orb.detectAndCompute(gray, None)\n",
    "    ps = np.array([keypoint.pt for keypoint in keypoints]).reshape(-1, 1, 2).astype('float32')\n",
    "\n",
    "    return ps\n",
    "\n",
    "def appendVertex(p0, p_add, min_dis):\n",
    "    '''\n",
    "    根据4邻域距离加入新的角点\n",
    "    '''\n",
    "    p_ret = p0.copy()\n",
    "    for p in p_add:\n",
    "        vec = p0 - p\n",
    "        dis = abs(vec[:, 0, 0]) + abs(vec[:, 0, 1])\n",
    "        if all(dis > min_dis):\n",
    "            p_ret = np.vstack((p_ret, p.reshape(-1, 1, 2)))\n",
    "    \n",
    "    add_num = p_ret.shape[0] - p0.shape[0]\n",
    "\n",
    "    return p_ret, add_num\n",
    "\n",
    "\n",
    "def sharpen(img):\n",
    "    '''\n",
    "    锐化图像\n",
    "    '''\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32) #定义一个核\n",
    "    sharpened = cv2.filter2D(img, -1, kernel=kernel)\n",
    "\n",
    "    return sharpened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findVertex(src):\n",
    "    '''\n",
    "    利用orb找特征点，利用稀疏光流跟踪找出背景角点，背景角点的特\n",
    "    征的是移动缓慢，当角点速度小于阈值的时\n",
    "    间大于200帧时即视为背景角点，并允许中间\n",
    "    帧加入的角点，速度较慢。\n",
    "\n",
    "    :param src  : 视频地址\n",
    "    :type src   : String\n",
    "    :returns    : 留存时间大于200的角点，\n",
    "                  格式为(frame_num, p_num, 2)\n",
    "                  若当前帧没有该角点，\n",
    "                  则补充[-1, -1]\n",
    "    '''\n",
    "    start = time()\n",
    "\n",
    "    # 读取视频\n",
    "    cap = cv2.VideoCapture(src)\n",
    "\n",
    "    # ShiTomasi 角点检测参数\n",
    "    feature_params = dict(maxCorners=1000,\n",
    "                            qualityLevel=0.3,\n",
    "                            minDistance=20,\n",
    "                            blockSize=7)\n",
    "\n",
    "    # lucas kanade光流法参数\n",
    "    lk_params = dict(winSize=(15, 15),\n",
    "                        maxLevel=2,\n",
    "                        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    # 创建随机颜色\n",
    "    color = np.random.randint(0, 255, (3000, 3))\n",
    "\n",
    "    # for i in range(0):\n",
    "    #     _, _ = cap.read()\n",
    "\n",
    "    # 获取第一帧，找到角点\n",
    "    ret, old_frame = cap.read()\n",
    "\n",
    "    # 找到原始灰度图\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    old_gray = sharpen(old_gray)\n",
    "    old_gray = cv2.equalizeHist(old_gray)\n",
    "\n",
    "    # # 获取图像中的角点，返回到p0中\n",
    "    # p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "\n",
    "    p0 = orbFeature(old_frame)\n",
    "\n",
    "    # 创建一个蒙版用来画轨迹\n",
    "    mask = np.zeros_like(old_frame)\n",
    "\n",
    "    flags = [np.ones(len(p0))]  # 选取的角点标号\n",
    "    ps = [p0[:,0]] # 保存角点\n",
    "    out_indexs = np.array([]) # 中途超速的点索引\n",
    "\n",
    "    while(1):\n",
    "        ret, frame = cap.read()\n",
    "        if type(frame) is type(None):\n",
    "            break\n",
    "        # frame = frame[332: ,718:, :]\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame_gray = sharpen(frame_gray)\n",
    "        frame_gray = cv2.equalizeHist(frame_gray)\n",
    "\n",
    "        # 计算光流\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "            old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "        # 寻找移动小于5的跟踪点\n",
    "        movement = p1 - p0\n",
    "        mag, ang = cv2.cartToPolar(movement[..., 0], movement[..., 1])\n",
    "\n",
    "        # 选取好的跟踪点\n",
    "        index = (st == 1) & (mag < 5)\n",
    "        flag = np.zeros_like(flags[-1])\n",
    "        flag[np.where(flags[-1] == 1)[0][index.flatten()]] = 1\n",
    "\n",
    "        good_new = p1[index]\n",
    "        good_old = p0[index]\n",
    "\n",
    "        # 若有点速度大于阈值，则将其过去痕迹也抹去\n",
    "        out_index = np.where(flags[-1] == 1)[0][((st == 1) & (mag >= 5)).flatten()]\n",
    "        out_indexs = np.append(out_indexs, out_index)\n",
    "\n",
    "        # 画出轨迹\n",
    "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            mask = cv2.line(mask, (a, b), (c, d), color[i].tolist(), 2)\n",
    "            frame = cv2.circle(frame, (a, b), 5, color[i].tolist(), -1)\n",
    "        img = cv2.add(frame, mask)\n",
    "\n",
    "        # 展示\n",
    "        cv2.imshow('frame', img)\n",
    "        # cv2.imshow('frame_gray', frame_gray)\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "        # 更新上一帧的图像和追踪点\n",
    "        old_gray = frame_gray.copy()\n",
    "        # p_add = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "        p_add = orbFeature(frame)\n",
    "        p0 = good_new.reshape(-1, 1, 2)\n",
    "        p0, add_num = appendVertex(p0, p_add, feature_params['minDistance'] / 1.414)\n",
    "        flag = np.append(flag, np.ones(add_num))\n",
    "        flags.append(flag.astype('int'))\n",
    "        ps.append(p0[:, 0])\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "\n",
    "    # -----------将留存时间不够长的的点去掉------------\n",
    "\n",
    "    # 最小留存时间\n",
    "    min_duration = 50\n",
    "\n",
    "    # 统计每个点的留存时间\n",
    "    duration = np.zeros(flags[-1].shape)\n",
    "    for flag in flags:\n",
    "        duration[np.where(flag == 1)[0]] += 1\n",
    "\n",
    "    # 将有效角点对应起来，若当前帧没有该角点，补充为[-1, -1]\n",
    "    valid_index = np.where(duration > min_duration)[0]\n",
    "    valid_index = np.array([index for index in valid_index if index not in out_indexs])\n",
    "\n",
    "    bg_ps = []\n",
    "    junk_p = np.array([-1, -1], dtype = 'int')\n",
    "    for flag, p in zip(flags, ps):\n",
    "        bg_p = []\n",
    "        for index in valid_index:\n",
    "            try:\n",
    "                if flag[index] == 0:\n",
    "                    bg_p.append(junk_p)\n",
    "                else:\n",
    "                    bg_p.append(p[int(sum(flag[: index]))])\n",
    "            except:\n",
    "                bg_p.append(junk_p)\n",
    "\n",
    "        bg_ps.append(bg_p)\n",
    "\n",
    "    bg_ps = np.asarray(bg_ps)\n",
    "    print('vertex find complete in ', time() - start)\n",
    "    return bg_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "vertex find complete in  35.72546195983887\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(503, 66, 2)"
     },
     "metadata": {},
     "execution_count": 318
    }
   ],
   "source": [
    "vertex = findVertex('video.avi')\n",
    "\n",
    "# 保存为二进制文件\n",
    "np.save('vertex', vertex)\n",
    "\n",
    "# 展示帧间有效点数的Demo\n",
    "stride = 3\n",
    "flags = []\n",
    "for i in np.arange(1, 503 - stride + 1):\n",
    "    id_ref = i\n",
    "    id_img = i + stride\n",
    "    flag = (np.sum(vertex[id_img - 1], axis = 1) >= 0) & (np.sum(vertex[id_ref - 1], axis = 1) >= 0)\n",
    "    flags.append(sum(flag))\n",
    "\n",
    "plt.plot(flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayVertex('video.avi', vertex, mode = 'run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignImg(vertex, ref, img, id_ref, id_img, fill = 1):\n",
    "    '''\n",
    "    :param vertex   :\n",
    "    :param ref      :\n",
    "    :param img      :\n",
    "    :param :\n",
    "    根据输入特征点计算单应性矩阵并对齐\n",
    "    '''\n",
    "    flag = (np.sum(vertex[id_img - 1], axis = 1) >= 0) & (np.sum(vertex[id_ref - 1], axis = 1) >= 0)\n",
    "    p_img = vertex[id_img - 1][flag]\n",
    "    p_ref = vertex[id_ref - 1][flag]\n",
    "\n",
    "    # 计算单应性矩阵\n",
    "    h, mask = cv2.findHomography(p_img, p_ref, cv2.RANSAC)\n",
    "    # 变换\n",
    "    height, width = img.shape[: 2]\n",
    "    img_reg = cv2.warpPerspective(img, h, (width, height))\n",
    "\n",
    "    if fill:\n",
    "        ref_mb = cv2.medianBlur(ref, 21)\n",
    "        img_reg = np.where(img_reg == 0, ref_mb, img_reg)\n",
    "\n",
    "    \n",
    "    vec = np.mean(p_img - p_ref, axis = 0)\n",
    "    mag = np.sqrt(vec[0] ** 2 + vec[1] ** 2)\n",
    "\n",
    "    return img_reg, mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignImgD(vertex, ref, img, id_ref, id_img, fill = 1):\n",
    "    '''\n",
    "    :param vertex   :\n",
    "    :param ref      :\n",
    "    :param img      :\n",
    "    :param :\n",
    "    根据输入特征点，分左右两侧分别计算单应性矩阵并对齐\n",
    "    '''\n",
    "    flag = (np.sum(vertex[id_img - 1], axis = 1) >= 0) & (np.sum(vertex[id_ref - 1], axis = 1) >= 0)\n",
    "    p_img = vertex[id_img - 1][flag]\n",
    "    p_ref = vertex[id_ref - 1][flag]\n",
    "    \n",
    "    height, width = img.shape[: 2]\n",
    "    th = width / 2\n",
    "\n",
    "    flag1 = (p_img[:, 0] < th) & (p_ref[:, 0] < th)\n",
    "    flag2 = (p_img[:, 0] >= th) & (p_ref[:, 0] >= th)\n",
    "\n",
    "    #------------------------------\n",
    "\n",
    "    p_img1 = p_img[flag1]\n",
    "    p_ref1 = p_ref[flag1]\n",
    "\n",
    "    # 计算单应性矩阵\n",
    "    h1, mask1 = cv2.findHomography(p_img1, p_ref1, cv2.RANSAC)\n",
    "    # 变换\n",
    "    img_reg1 = cv2.warpPerspective(img, h1, (width, height))\n",
    "\n",
    "    if fill:\n",
    "        ref_mb1 = cv2.medianBlur(ref, 21)\n",
    "        img_reg1 = np.where(img_reg1 == 0, ref_mb1, img_reg1)\n",
    "    \n",
    "    vec1 = np.mean(p_img1 - p_ref1, axis = 0)\n",
    "    mag1 = np.sqrt(vec1[0] ** 2 + vec1[1] ** 2)\n",
    "\n",
    "    #------------------------------\n",
    "\n",
    "    p_img2 = p_img[flag2]\n",
    "    p_ref2 = p_ref[flag2]\n",
    "\n",
    "    # 计算单应性矩阵\n",
    "    h2, mask2 = cv2.findHomography(p_img2, p_ref2, cv2.RANSAC)\n",
    "    # 变换\n",
    "    img_reg2 = cv2.warpPerspective(img, h2, (width, height))\n",
    "\n",
    "    if fill:\n",
    "        ref_mb2 = cv2.medianBlur(ref, 21)\n",
    "        img_reg2 = np.where(img_reg2 == 0, ref_mb2, img_reg2)\n",
    "\n",
    "    vec2 = np.mean(p_img2 - p_ref2, axis = 0)\n",
    "    mag2 = np.sqrt(vec2[0] ** 2 + vec2[1] ** 2)\n",
    "\n",
    "    mag = (mag1 + mag2) / 2\n",
    "    img_reg = img_reg1.copy()\n",
    "    img_reg[:, int(th): ] = img_reg2[:, int(th): ]\n",
    "\n",
    "    return img_reg, mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignImgC(vertex, ref, img, id_ref, id_img, fill = 1, p_th = 30):\n",
    "    '''\n",
    "    :param vertex   : 特征点\n",
    "    :param ref      : 参照图像\n",
    "    :param img      : 待处理图像\n",
    "    :param id_ref   : 参照图象的id，从1开始数\n",
    "    :param id_img   : 待处理图像的id，从1开始数\n",
    "    :param fill     : 1表示用参照图象的中值滤波填充，0表示用白色填充\n",
    "    :param p_th     : 取外沿特征点的数量（实际会稍大于p_th）\n",
    "    根据输入特征点，从外沿向内取一定数量的点，\n",
    "    计算单应性矩阵并对齐\n",
    "    '''\n",
    "    # 可用特征点\n",
    "    flag = (np.sum(vertex[id_img - 1], axis = 1) >= 0) & (np.sum(vertex[id_ref - 1], axis = 1) >= 0)\n",
    "    p_th = sum(flag) if sum(flag) < p_th else p_th\n",
    "    p_img = vertex[id_img - 1][flag]\n",
    "    p_ref = vertex[id_ref - 1][flag]\n",
    "\n",
    "    # 计算平均移动距离\n",
    "    vec = np.mean(p_img - p_ref, axis = 0)\n",
    "    mag = np.sqrt(vec[0] ** 2 + vec[1] ** 2)\n",
    "\n",
    "    # 从外沿向内取一定数量的点\n",
    "    p_num = 0\n",
    "    p_ref_conv = np.empty((0, 2))\n",
    "    p_img_conv = np.empty((0, 2))\n",
    "\n",
    "    while p_num < p_th:\n",
    "        flag_conv = cv2.convexHull(p_ref.reshape(1, -1, 2).astype('int'), returnPoints = False).flatten()\n",
    "        p_num += len(flag_conv)\n",
    "\n",
    "        p_ref_conv = np.append(p_ref_conv, p_ref[flag_conv], axis = 0)\n",
    "        p_img_conv = np.append(p_img_conv, p_img[flag_conv], axis = 0)\n",
    "\n",
    "        deflag_conv = [i not in flag_conv for i in range(len(p_ref))]\n",
    "        p_ref = p_ref[deflag_conv]\n",
    "        p_img = p_img[deflag_conv]\n",
    "\n",
    "    # 计算单应性矩阵\n",
    "    # h, mask = cv2.findHomography(p_img_conv, p_ref_conv, cv2.RANSAC, ransacReprojThreshold = mag)\n",
    "    h, mask = cv2.findHomography(p_img_conv, p_ref_conv, method = 0)\n",
    "    # 变换\n",
    "    height, width = img.shape[: 2]\n",
    "\n",
    "    if fill:\n",
    "        img_reg = cv2.warpPerspective(img, h, (width, height), flags = cv2.INTER_NEAREST)\n",
    "        ref_mb = cv2.medianBlur(ref, 21)\n",
    "        img_reg = np.where(img_reg == 0, ref_mb, img_reg)\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            channel = img.shape[2]\n",
    "        except:\n",
    "            channel = 1\n",
    "        img_reg = cv2.warpPerspective(img, h, (width, height), flags = cv2.INTER_NEAREST, borderValue = [255] * channel)\n",
    "\n",
    "    return img_reg, mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alignC Demo\n",
    "color = np.random.randint(0, 255, (1000, 3))\n",
    "\n",
    "i = 251\n",
    "stride = 3\n",
    "ref = cv2.imread(f'frames/frame_{i}.jpg')\n",
    "img = cv2.imread(f'frames/frame_{i + stride}.jpg')\n",
    "\n",
    "id_ref = i\n",
    "id_img = i + stride\n",
    "\n",
    "flag = (np.sum(vertex[id_img - 1], axis = 1) >= 0) & (np.sum(vertex[id_ref - 1], axis = 1) >= 0)\n",
    "p_img = vertex[id_img - 1][flag]\n",
    "p_ref = vertex[id_ref - 1][flag]\n",
    "\n",
    "p_th = 30\n",
    "p_th = sum(flag) if sum(flag) < p_th else p_th\n",
    "p_num = 0\n",
    "p_ref_conv = np.empty((0, 2))\n",
    "p_img_conv = np.empty((0, 2))\n",
    "\n",
    "while p_num < p_th:\n",
    "    flag_conv = cv2.convexHull(p_ref.reshape(1, -1, 2).astype('int'), returnPoints = False).flatten()\n",
    "    p_num += len(flag_conv)\n",
    "\n",
    "    p_ref_conv = np.append(p_ref_conv, p_ref[flag_conv], axis = 0)\n",
    "    p_img_conv = np.append(p_img_conv, p_img[flag_conv], axis = 0)\n",
    "\n",
    "    deflag_conv = [i not in flag_conv for i in range(len(p_ref))]\n",
    "    p_ref = p_ref[deflag_conv]\n",
    "    p_img = p_img[deflag_conv]\n",
    "\n",
    "# 画点\n",
    "for j, (new, old) in enumerate(zip(p_img_conv, p_ref_conv)):\n",
    "    a, b = old.ravel().astype('int')\n",
    "    c, d = new.ravel().astype('int')\n",
    "    ref = cv2.circle(ref, (a, b), 5, color[j].tolist(), -1)\n",
    "    img = cv2.circle(img, (c, d), 5, color[j].tolist(), -1)\n",
    "\n",
    "img_shift, _ = alignImgC(vertex, ref, img, i, i + stride, fill = 1, p_th = p_th)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('ref', ref)\n",
    "cv2.imshow('img_shift', img_shift)\n",
    "cv2.moveWindow('img', 0, 0)\n",
    "cv2.moveWindow('ref', 0, 0)\n",
    "cv2.moveWindow('img_shift', 0, 0)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alignD Demo\n",
    "i = 295\n",
    "stride = 30\n",
    "ref = cv2.imread(f'frames/frame_{i}.jpg')\n",
    "img = cv2.imread(f'frames/frame_{i + stride}.jpg')\n",
    "\n",
    "img_shift, _ = alignImgD(vertex, ref, img, i, i + stride, fill = 1)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('ref', ref)\n",
    "cv2.imshow('img_shift', img_shift)\n",
    "cv2.moveWindow('img', 0, 0)\n",
    "cv2.moveWindow('ref', 0, 0)\n",
    "cv2.moveWindow('img_shift', 0, 0)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.10276579856872559\n"
    }
   ],
   "source": [
    "# align Demo\n",
    "i = 16\n",
    "stride = 3\n",
    "ref = cv2.imread(f'frames/frame_{i}.jpg')\n",
    "img = cv2.imread(f'frames/frame_{i + stride}.jpg')\n",
    "\n",
    "img_shift, _ = alignImg(vertex, ref, img, i, i + stride, fill = 1)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('ref', ref)\n",
    "cv2.imshow('img_shift', img_shift)\n",
    "cv2.moveWindow('img', 0, 0)\n",
    "cv2.moveWindow('ref', 0, 0)\n",
    "cv2.moveWindow('img_shift', 0, 0)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 0, -1,  1, -2,  2, -3,  3, -4,  4, -5,  5, -6,  6])"
     },
     "metadata": {},
     "execution_count": 427
    }
   ],
   "source": [
    "source = np.arange(-6, 7, 1)\n",
    "source[np.argsort(np.abs(source))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1],\n       [0],\n       [0]], dtype=uint8)"
     },
     "metadata": {},
     "execution_count": 486
    }
   ],
   "source": [
    "a = np.array([1,2,3], dtype = 'uint8')\n",
    "b = np.array([2,2,3], dtype = 'uint8')\n",
    "cv2.subtract(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}